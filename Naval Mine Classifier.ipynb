{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Heet Gorakhitya/Downloads/sonar.csv\")\n",
    "#df.head()\n",
    "X = df[df.columns[0:60]].values\n",
    "y = df[df.columns[60]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "Y = one_hot_encode(y)\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv(\"C:/Users/Heet Gorakhitya/Downloads/sonar.csv\")\n",
    "    X = df[df.columns[0:60]].values\n",
    "    y = df[df.columns[60]]\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)    \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 60)\n",
      "(165, 2)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X, Y = read_dataset()\n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0.2, random_state=415)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(train_y[100][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "epochs = 1000\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "n_dims = X.shape[1]\n",
    "classes = 2\n",
    "model_path = \"C:/Users/Heet Gorakhitya/Desktop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_dim = X.shape[1]\n",
    "#n_dim\n",
    "x = tf.placeholder(tf.float32, [None, n_dims])\n",
    "W = tf.Variable(tf.zeros([n_dims, classes]))\n",
    "b = tf.Variable(tf.zeros([classes]))\n",
    "y_ = tf.placeholder(tf.float32, [None, classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "\n",
    "    out_layer = tf.add(tf.matmul(layer_4, weights['out']), biases['out'])\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dims, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, classes])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([classes])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "y = multilayer_perceptron(x, weights, biases)\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "#training_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 - Cost:  239.31018  - MSE:  47711.93464233927 - Train Accuracy:  0.45454547\n",
      "Epoch:  1 - Cost:  1.9997829  - MSE:  19.284789978863465 - Train Accuracy:  0.54545456\n",
      "Epoch:  2 - Cost:  35.65419  - MSE:  1055.1204404743673 - Train Accuracy:  0.45454547\n",
      "Epoch:  3 - Cost:  4.6122518  - MSE:  41.50482264220794 - Train Accuracy:  0.54545456\n",
      "Epoch:  4 - Cost:  1.119775  - MSE:  1.0552326449814107 - Train Accuracy:  0.45454547\n",
      "Epoch:  5 - Cost:  0.8265998  - MSE:  1.4549185329954728 - Train Accuracy:  0.45454547\n",
      "Epoch:  6 - Cost:  0.78324  - MSE:  1.2586927724923016 - Train Accuracy:  0.45454547\n",
      "Epoch:  7 - Cost:  0.747087  - MSE:  0.9604832636846199 - Train Accuracy:  0.45454547\n",
      "Epoch:  8 - Cost:  0.71560395  - MSE:  0.6515838560483419 - Train Accuracy:  0.45454547\n",
      "Epoch:  9 - Cost:  0.69150287  - MSE:  0.418107188991777 - Train Accuracy:  0.46060607\n",
      "Epoch:  10 - Cost:  0.6788793  - MSE:  0.30963918540609525 - Train Accuracy:  0.6606061\n",
      "Epoch:  11 - Cost:  0.6751417  - MSE:  0.28574865007070177 - Train Accuracy:  0.56363636\n",
      "Epoch:  12 - Cost:  0.6740785  - MSE:  0.2874601633719864 - Train Accuracy:  0.54545456\n",
      "Epoch:  13 - Cost:  0.67317617  - MSE:  0.2969804909083209 - Train Accuracy:  0.55151516\n",
      "Epoch:  14 - Cost:  0.6721114  - MSE:  0.31236533713907105 - Train Accuracy:  0.55151516\n",
      "Epoch:  15 - Cost:  0.670872  - MSE:  0.33407803073229614 - Train Accuracy:  0.56363636\n",
      "Epoch:  16 - Cost:  0.6696537  - MSE:  0.3595783175734233 - Train Accuracy:  0.56969696\n",
      "Epoch:  17 - Cost:  0.66854346  - MSE:  0.3776217819176444 - Train Accuracy:  0.57575756\n",
      "Epoch:  18 - Cost:  0.6673686  - MSE:  0.39758144656548744 - Train Accuracy:  0.58787876\n",
      "Epoch:  19 - Cost:  0.6661058  - MSE:  0.41893048356271684 - Train Accuracy:  0.5939394\n",
      "Epoch:  20 - Cost:  0.6646999  - MSE:  0.4477277896503888 - Train Accuracy:  0.6242424\n",
      "Epoch:  21 - Cost:  0.663254  - MSE:  0.47551156667484384 - Train Accuracy:  0.6424242\n",
      "Epoch:  22 - Cost:  0.6617457  - MSE:  0.5017525645982662 - Train Accuracy:  0.6545454\n",
      "Epoch:  23 - Cost:  0.6601703  - MSE:  0.5268223966518577 - Train Accuracy:  0.6424242\n",
      "Epoch:  24 - Cost:  0.65851086  - MSE:  0.5545537085236586 - Train Accuracy:  0.6666667\n",
      "Epoch:  25 - Cost:  0.6567675  - MSE:  0.5824881146862567 - Train Accuracy:  0.6666667\n",
      "Epoch:  26 - Cost:  0.6549569  - MSE:  0.6076542818437974 - Train Accuracy:  0.6727273\n",
      "Epoch:  27 - Cost:  0.653061  - MSE:  0.6359312348735455 - Train Accuracy:  0.6727273\n",
      "Epoch:  28 - Cost:  0.65107805  - MSE:  0.663087835905665 - Train Accuracy:  0.6727273\n",
      "Epoch:  29 - Cost:  0.6490145  - MSE:  0.6914562316268833 - Train Accuracy:  0.6727273\n",
      "Epoch:  30 - Cost:  0.6468769  - MSE:  0.7150839054176683 - Train Accuracy:  0.6787879\n",
      "Epoch:  31 - Cost:  0.6446699  - MSE:  0.7348909237585864 - Train Accuracy:  0.6787879\n",
      "Epoch:  32 - Cost:  0.6423777  - MSE:  0.7614889756364137 - Train Accuracy:  0.6787879\n",
      "Epoch:  33 - Cost:  0.6399993  - MSE:  0.7809391720045129 - Train Accuracy:  0.6727273\n",
      "Epoch:  34 - Cost:  0.6375357  - MSE:  0.8094766703559694 - Train Accuracy:  0.6727273\n",
      "Epoch:  35 - Cost:  0.63498664  - MSE:  0.8260550493670082 - Train Accuracy:  0.6787879\n",
      "Epoch:  36 - Cost:  0.6323577  - MSE:  0.8608846815352811 - Train Accuracy:  0.7030303\n",
      "Epoch:  37 - Cost:  0.62965834  - MSE:  0.8603908611185981 - Train Accuracy:  0.6909091\n",
      "Epoch:  38 - Cost:  0.6269303  - MSE:  0.9319005955653672 - Train Accuracy:  0.6909091\n",
      "Epoch:  39 - Cost:  0.624346  - MSE:  0.8589310421583773 - Train Accuracy:  0.6909091\n",
      "Epoch:  40 - Cost:  0.62305593  - MSE:  1.1184864658624458 - Train Accuracy:  0.7030303\n",
      "Epoch:  41 - Cost:  0.6308308  - MSE:  0.6771375796081417 - Train Accuracy:  0.6787879\n",
      "Epoch:  42 - Cost:  0.7007384  - MSE:  2.3525634961900104 - Train Accuracy:  0.4969697\n",
      "Epoch:  43 - Cost:  0.96965283  - MSE:  1.698679454483656 - Train Accuracy:  0.54545456\n",
      "Epoch:  44 - Cost:  0.76950496  - MSE:  2.4573328103092447 - Train Accuracy:  0.45454547\n",
      "Epoch:  45 - Cost:  0.727273  - MSE:  1.656065782041256 - Train Accuracy:  0.45454547\n",
      "Epoch:  46 - Cost:  0.7140884  - MSE:  1.6680058467109378 - Train Accuracy:  0.45454547\n",
      "Epoch:  47 - Cost:  0.70239687  - MSE:  1.7342277513043096 - Train Accuracy:  0.45454547\n",
      "Epoch:  48 - Cost:  0.6936356  - MSE:  1.8200022218579923 - Train Accuracy:  0.45454547\n",
      "Epoch:  49 - Cost:  0.68729484  - MSE:  1.8699398927793554 - Train Accuracy:  0.45454547\n",
      "Epoch:  50 - Cost:  0.6825774  - MSE:  1.9378349869393199 - Train Accuracy:  0.45454547\n",
      "Epoch:  51 - Cost:  0.6788923  - MSE:  1.8384573625874285 - Train Accuracy:  0.6424242\n",
      "Epoch:  52 - Cost:  0.67546916  - MSE:  1.9766521224096723 - Train Accuracy:  0.6121212\n",
      "Epoch:  53 - Cost:  0.67322457  - MSE:  1.8509085141387225 - Train Accuracy:  0.6848485\n",
      "Epoch:  54 - Cost:  0.6708643  - MSE:  2.061524839253908 - Train Accuracy:  0.6424242\n",
      "Epoch:  55 - Cost:  0.6679743  - MSE:  1.9061750021829327 - Train Accuracy:  0.6787879\n",
      "Epoch:  56 - Cost:  0.6661098  - MSE:  2.0559864683110254 - Train Accuracy:  0.6787879\n",
      "Epoch:  57 - Cost:  0.6640612  - MSE:  1.9320126649184413 - Train Accuracy:  0.7030303\n",
      "Epoch:  58 - Cost:  0.6621851  - MSE:  2.078133915356551 - Train Accuracy:  0.6909091\n",
      "Epoch:  59 - Cost:  0.66006553  - MSE:  1.9772636261846643 - Train Accuracy:  0.7030303\n",
      "Epoch:  60 - Cost:  0.65863436  - MSE:  2.123698325149052 - Train Accuracy:  0.6909091\n",
      "Epoch:  61 - Cost:  0.6568839  - MSE:  1.96516601213851 - Train Accuracy:  0.6909091\n",
      "Epoch:  62 - Cost:  0.6561754  - MSE:  2.2391741665431524 - Train Accuracy:  0.6727273\n",
      "Epoch:  63 - Cost:  0.6539425  - MSE:  1.957464167386657 - Train Accuracy:  0.6727273\n",
      "Epoch:  64 - Cost:  0.65297747  - MSE:  2.2862103330071415 - Train Accuracy:  0.6545454\n",
      "Epoch:  65 - Cost:  0.65136665  - MSE:  1.94868333093934 - Train Accuracy:  0.6666667\n",
      "Epoch:  66 - Cost:  0.6533008  - MSE:  2.4672917057974915 - Train Accuracy:  0.6606061\n",
      "Epoch:  67 - Cost:  0.6533581  - MSE:  1.8904466562147857 - Train Accuracy:  0.6545454\n",
      "Epoch:  68 - Cost:  0.6532568  - MSE:  2.585743982075282 - Train Accuracy:  0.6545454\n",
      "Epoch:  69 - Cost:  0.65486336  - MSE:  1.8588008407340333 - Train Accuracy:  0.6363636\n",
      "Epoch:  70 - Cost:  0.6471788  - MSE:  2.516672225370746 - Train Accuracy:  0.630303\n",
      "Epoch:  71 - Cost:  0.65117884  - MSE:  1.8861333638737379 - Train Accuracy:  0.6484848\n",
      "Epoch:  72 - Cost:  0.64530724  - MSE:  2.563734253522324 - Train Accuracy:  0.6666667\n",
      "Epoch:  73 - Cost:  0.6516907  - MSE:  1.8666472151595406 - Train Accuracy:  0.630303\n",
      "Epoch:  74 - Cost:  0.64577854  - MSE:  2.662909779022844 - Train Accuracy:  0.6606061\n",
      "Epoch:  75 - Cost:  0.65779185  - MSE:  1.825635037296194 - Train Accuracy:  0.6181818\n",
      "Epoch:  76 - Cost:  0.65438676  - MSE:  2.9056947492280463 - Train Accuracy:  0.57575756\n",
      "Epoch:  77 - Cost:  0.6735083  - MSE:  1.7776932724814714 - Train Accuracy:  0.57575756\n",
      "Epoch:  78 - Cost:  0.6375752  - MSE:  2.625412305794192 - Train Accuracy:  0.6363636\n",
      "Epoch:  79 - Cost:  0.6479447  - MSE:  1.8936374705674228 - Train Accuracy:  0.6363636\n",
      "Epoch:  80 - Cost:  0.6440065  - MSE:  2.8360420013476246 - Train Accuracy:  0.6363636\n",
      "Epoch:  81 - Cost:  0.6682868  - MSE:  1.8065868940518237 - Train Accuracy:  0.5939394\n",
      "Epoch:  82 - Cost:  0.64003056  - MSE:  2.8197151095163258 - Train Accuracy:  0.6606061\n",
      "Epoch:  83 - Cost:  0.664634  - MSE:  1.823961517026918 - Train Accuracy:  0.6\n",
      "Epoch:  84 - Cost:  0.65097535  - MSE:  3.066914458130959 - Train Accuracy:  0.56969696\n",
      "Epoch:  85 - Cost:  0.6817364  - MSE:  1.7856868375103714 - Train Accuracy:  0.55757576\n",
      "Epoch:  86 - Cost:  0.6220658  - MSE:  2.450076861226534 - Train Accuracy:  0.6969697\n",
      "Epoch:  87 - Cost:  0.62197465  - MSE:  2.1458328621355194 - Train Accuracy:  0.6787879\n",
      "Epoch:  88 - Cost:  0.6396312  - MSE:  2.978487377429741 - Train Accuracy:  0.6363636\n",
      "Epoch:  89 - Cost:  0.6788069  - MSE:  1.8044152398991062 - Train Accuracy:  0.56969696\n",
      "Epoch:  90 - Cost:  0.6186391  - MSE:  2.5712360525860256 - Train Accuracy:  0.6545454\n",
      "Epoch:  91 - Cost:  0.62691885  - MSE:  2.0453716805235467 - Train Accuracy:  0.6909091\n",
      "Epoch:  92 - Cost:  0.6554418  - MSE:  3.278116447494211 - Train Accuracy:  0.53333336\n",
      "Epoch:  93 - Cost:  0.7050443  - MSE:  1.7471946217109915 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  94 - Cost:  0.64803493  - MSE:  1.8913542884130214 - Train Accuracy:  0.6242424\n",
      "Epoch:  95 - Cost:  0.6543096  - MSE:  3.2815927191893204 - Train Accuracy:  0.53333336\n",
      "Epoch:  96 - Cost:  0.7008085  - MSE:  1.7487822180154862 - Train Accuracy:  0.54545456\n",
      "Epoch:  97 - Cost:  0.6417286  - MSE:  1.9162027621082192 - Train Accuracy:  0.6424242\n",
      "Epoch:  98 - Cost:  0.65317225  - MSE:  3.294768795553991 - Train Accuracy:  0.55757576\n",
      "Epoch:  99 - Cost:  0.6977649  - MSE:  1.7527198357942293 - Train Accuracy:  0.54545456\n",
      "Epoch:  100 - Cost:  0.63655925  - MSE:  1.9427260817526981 - Train Accuracy:  0.6424242\n",
      "Epoch:  101 - Cost:  0.6342123  - MSE:  3.058150441964017 - Train Accuracy:  0.6424242\n",
      "Epoch:  102 - Cost:  0.67755353  - MSE:  1.8082400946080235 - Train Accuracy:  0.58181816\n",
      "Epoch:  103 - Cost:  0.61017126  - MSE:  2.6287000634987523 - Train Accuracy:  0.6545454\n",
      "Epoch:  104 - Cost:  0.6202824  - MSE:  2.071314773409035 - Train Accuracy:  0.7151515\n",
      "Epoch:  105 - Cost:  0.63109726  - MSE:  3.111867420097751 - Train Accuracy:  0.6424242\n",
      "Epoch:  106 - Cost:  0.685614  - MSE:  1.7998226889921802 - Train Accuracy:  0.56969696\n",
      "Epoch:  107 - Cost:  0.6036289  - MSE:  2.278181730832813 - Train Accuracy:  0.73333335\n",
      "Epoch:  108 - Cost:  0.6254247  - MSE:  3.0943100500016425 - Train Accuracy:  0.6484848\n",
      "Epoch:  109 - Cost:  0.6824166  - MSE:  1.815565642652546 - Train Accuracy:  0.58181816\n",
      "Epoch:  110 - Cost:  0.59712  - MSE:  2.437597953765626 - Train Accuracy:  0.72121215\n",
      "Epoch:  111 - Cost:  0.59483445  - MSE:  2.4043008468583786 - Train Accuracy:  0.73939395\n",
      "Epoch:  112 - Cost:  0.59651995  - MSE:  2.673481722816854 - Train Accuracy:  0.6666667\n",
      "Epoch:  113 - Cost:  0.61324465  - MSE:  2.0702729622266625 - Train Accuracy:  0.6969697\n",
      "Epoch:  114 - Cost:  0.6100802  - MSE:  3.0105502431206257 - Train Accuracy:  0.6606061\n",
      "Epoch:  115 - Cost:  0.6824029  - MSE:  1.825261142893349 - Train Accuracy:  0.5939394\n",
      "Epoch:  116 - Cost:  0.59025383  - MSE:  2.658826629769634 - Train Accuracy:  0.6666667\n",
      "Epoch:  117 - Cost:  0.6117103  - MSE:  2.0468156988280626 - Train Accuracy:  0.6848485\n",
      "Epoch:  118 - Cost:  0.633102  - MSE:  3.359927796574579 - Train Accuracy:  0.630303\n",
      "Epoch:  119 - Cost:  0.7221419  - MSE:  1.758529450609229 - Train Accuracy:  0.54545456\n",
      "Epoch:  120 - Cost:  0.68705636  - MSE:  1.7802719579085102 - Train Accuracy:  0.58181816\n",
      "Epoch:  121 - Cost:  0.60314095  - MSE:  2.0772998715360633 - Train Accuracy:  0.7151515\n",
      "Epoch:  122 - Cost:  0.6085876  - MSE:  3.0208910662813726 - Train Accuracy:  0.6606061\n",
      "Epoch:  123 - Cost:  0.6826554  - MSE:  1.7877104815017268 - Train Accuracy:  0.5939394\n",
      "Epoch:  124 - Cost:  0.5912098  - MSE:  2.2117175973531285 - Train Accuracy:  0.73333335\n",
      "Epoch:  125 - Cost:  0.5987697  - MSE:  2.9466446700349462 - Train Accuracy:  0.6666667\n",
      "Epoch:  126 - Cost:  0.67708063  - MSE:  1.8032216672008141 - Train Accuracy:  0.6060606\n",
      "Epoch:  127 - Cost:  0.5835679  - MSE:  2.3023225634214386 - Train Accuracy:  0.74545455\n",
      "Epoch:  128 - Cost:  0.5952119  - MSE:  2.9687905282280895 - Train Accuracy:  0.6727273\n",
      "Epoch:  129 - Cost:  0.67812955  - MSE:  1.804356497422099 - Train Accuracy:  0.6060606\n",
      "Epoch:  130 - Cost:  0.5821526  - MSE:  2.269268472001411 - Train Accuracy:  0.73939395\n",
      "Epoch:  131 - Cost:  0.59896016  - MSE:  3.083205065708573 - Train Accuracy:  0.6787879\n",
      "Epoch:  132 - Cost:  0.6924427  - MSE:  1.7702651243436054 - Train Accuracy:  0.57575756\n",
      "Epoch:  133 - Cost:  0.5976851  - MSE:  2.0577732694472264 - Train Accuracy:  0.7151515\n",
      "Epoch:  134 - Cost:  0.6502898  - MSE:  3.6462716137007125 - Train Accuracy:  0.57575756\n",
      "Epoch:  135 - Cost:  0.7272262  - MSE:  1.7498997949450052 - Train Accuracy:  0.54545456\n",
      "Epoch:  136 - Cost:  0.717341  - MSE:  1.7217690427024195 - Train Accuracy:  0.54545456\n",
      "Epoch:  137 - Cost:  0.7099196  - MSE:  1.6999435859074274 - Train Accuracy:  0.54545456\n",
      "Epoch:  138 - Cost:  0.7043872  - MSE:  1.683009063694444 - Train Accuracy:  0.54545456\n",
      "Epoch:  139 - Cost:  0.70028627  - MSE:  1.6698502667576491 - Train Accuracy:  0.54545456\n",
      "Epoch:  140 - Cost:  0.6972598  - MSE:  1.6595986116398054 - Train Accuracy:  0.54545456\n",
      "Epoch:  141 - Cost:  0.69503504  - MSE:  1.651583550181585 - Train Accuracy:  0.54545456\n",
      "Epoch:  142 - Cost:  0.6934034  - MSE:  1.645290200973357 - Train Accuracy:  0.54545456\n",
      "Epoch:  143 - Cost:  0.6922101  - MSE:  1.6403249688371275 - Train Accuracy:  0.54545456\n",
      "Epoch:  144 - Cost:  0.69133836  - MSE:  1.6363871790677553 - Train Accuracy:  0.54545456\n",
      "Epoch:  145 - Cost:  0.690703  - MSE:  1.6332473931377098 - Train Accuracy:  0.54545456\n",
      "Epoch:  146 - Cost:  0.69024026  - MSE:  1.6307301818933997 - Train Accuracy:  0.54545456\n",
      "Epoch:  147 - Cost:  0.689903  - MSE:  1.6287011420675006 - Train Accuracy:  0.54545456\n",
      "Epoch:  148 - Cost:  0.6896586  - MSE:  1.6270569518345772 - Train Accuracy:  0.54545456\n",
      "Epoch:  149 - Cost:  0.68948054  - MSE:  1.6257178756493451 - Train Accuracy:  0.54545456\n",
      "Epoch:  150 - Cost:  0.6893514  - MSE:  1.6246220831683493 - Train Accuracy:  0.54545456\n",
      "Epoch:  151 - Cost:  0.68925726  - MSE:  1.6237213045978514 - Train Accuracy:  0.54545456\n",
      "Epoch:  152 - Cost:  0.6891892  - MSE:  1.6229779080331863 - Train Accuracy:  0.54545456\n",
      "Epoch:  153 - Cost:  0.6891399  - MSE:  1.6223620495125683 - Train Accuracy:  0.54545456\n",
      "Epoch:  154 - Cost:  0.6891039  - MSE:  1.621850111422739 - Train Accuracy:  0.54545456\n",
      "Epoch:  155 - Cost:  0.68907785  - MSE:  1.6214232741440864 - Train Accuracy:  0.54545456\n",
      "Epoch:  156 - Cost:  0.6890587  - MSE:  1.6210664197631612 - Train Accuracy:  0.54545456\n",
      "Epoch:  157 - Cost:  0.68904555  - MSE:  1.620767429824845 - Train Accuracy:  0.54545456\n",
      "Epoch:  158 - Cost:  0.6890353  - MSE:  1.6205162021804764 - Train Accuracy:  0.54545456\n",
      "Epoch:  159 - Cost:  0.68902797  - MSE:  1.6203048862738012 - Train Accuracy:  0.54545456\n",
      "Epoch:  160 - Cost:  0.68902314  - MSE:  1.6201268706864218 - Train Accuracy:  0.54545456\n",
      "Epoch:  161 - Cost:  0.6890192  - MSE:  1.6199765823467394 - Train Accuracy:  0.54545456\n",
      "Epoch:  162 - Cost:  0.6890166  - MSE:  1.6198495940252897 - Train Accuracy:  0.54545456\n",
      "Epoch:  163 - Cost:  0.6890143  - MSE:  1.6197421881149714 - Train Accuracy:  0.54545456\n",
      "Epoch:  164 - Cost:  0.6890131  - MSE:  1.61965125052226 - Train Accuracy:  0.54545456\n",
      "Epoch:  165 - Cost:  0.6890121  - MSE:  1.6195742070490624 - Train Accuracy:  0.54545456\n",
      "Epoch:  166 - Cost:  0.68901104  - MSE:  1.6195088813720437 - Train Accuracy:  0.54545456\n",
      "Epoch:  167 - Cost:  0.6890109  - MSE:  1.61945346242125 - Train Accuracy:  0.54545456\n",
      "Epoch:  168 - Cost:  0.68901  - MSE:  1.6194064218976862 - Train Accuracy:  0.54545456\n",
      "Epoch:  169 - Cost:  0.6890099  - MSE:  1.619366480772733 - Train Accuracy:  0.54545456\n",
      "Epoch:  170 - Cost:  0.68900996  - MSE:  1.6193325568388153 - Train Accuracy:  0.54545456\n",
      "Epoch:  171 - Cost:  0.6890095  - MSE:  1.6193037257612914 - Train Accuracy:  0.54545456\n",
      "Epoch:  172 - Cost:  0.6890098  - MSE:  1.6192792277061372 - Train Accuracy:  0.54545456\n",
      "Epoch:  173 - Cost:  0.68900955  - MSE:  1.6192583983126738 - Train Accuracy:  0.54545456\n",
      "Epoch:  174 - Cost:  0.68900967  - MSE:  1.619240688392454 - Train Accuracy:  0.54545456\n",
      "Epoch:  175 - Cost:  0.6890095  - MSE:  1.619225554402534 - Train Accuracy:  0.54545456\n",
      "Epoch:  176 - Cost:  0.6890094  - MSE:  1.6192127463124788 - Train Accuracy:  0.54545456\n",
      "Epoch:  177 - Cost:  0.6890093  - MSE:  1.6192018458524882 - Train Accuracy:  0.54545456\n",
      "Epoch:  178 - Cost:  0.6890096  - MSE:  1.619192576770453 - Train Accuracy:  0.54545456\n",
      "Epoch:  179 - Cost:  0.68900925  - MSE:  1.6191846857421066 - Train Accuracy:  0.54545456\n",
      "Epoch:  180 - Cost:  0.6890095  - MSE:  1.619177974761038 - Train Accuracy:  0.54545456\n",
      "Epoch:  181 - Cost:  0.6890091  - MSE:  1.6191721932157768 - Train Accuracy:  0.54545456\n",
      "Epoch:  182 - Cost:  0.68900925  - MSE:  1.619167401724945 - Train Accuracy:  0.54545456\n",
      "Epoch:  183 - Cost:  0.68900937  - MSE:  1.6191632658004178 - Train Accuracy:  0.54545456\n",
      "Epoch:  184 - Cost:  0.68900925  - MSE:  1.6191597401909175 - Train Accuracy:  0.54545456\n",
      "Epoch:  185 - Cost:  0.6890091  - MSE:  1.6191567483606673 - Train Accuracy:  0.54545456\n",
      "Epoch:  186 - Cost:  0.68900913  - MSE:  1.6191542030082584 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  187 - Cost:  0.6890093  - MSE:  1.6191520278017546 - Train Accuracy:  0.54545456\n",
      "Epoch:  188 - Cost:  0.68900925  - MSE:  1.619150179099692 - Train Accuracy:  0.54545456\n",
      "Epoch:  189 - Cost:  0.68900913  - MSE:  1.6191486773959483 - Train Accuracy:  0.54545456\n",
      "Epoch:  190 - Cost:  0.6890093  - MSE:  1.6191473400599554 - Train Accuracy:  0.54545456\n",
      "Epoch:  191 - Cost:  0.68900925  - MSE:  1.6191461985167237 - Train Accuracy:  0.54545456\n",
      "Epoch:  192 - Cost:  0.689009  - MSE:  1.619145230984275 - Train Accuracy:  0.54545456\n",
      "Epoch:  193 - Cost:  0.6890093  - MSE:  1.6191444048213433 - Train Accuracy:  0.54545456\n",
      "Epoch:  194 - Cost:  0.689009  - MSE:  1.6191436982671874 - Train Accuracy:  0.54545456\n",
      "Epoch:  195 - Cost:  0.6890092  - MSE:  1.619143100437116 - Train Accuracy:  0.54545456\n",
      "Epoch:  196 - Cost:  0.6890092  - MSE:  1.6191425895811804 - Train Accuracy:  0.54545456\n",
      "Epoch:  197 - Cost:  0.6890091  - MSE:  1.6191421548225335 - Train Accuracy:  0.54545456\n",
      "Epoch:  198 - Cost:  0.689009  - MSE:  1.6191417852866223 - Train Accuracy:  0.54545456\n",
      "Epoch:  199 - Cost:  0.6890091  - MSE:  1.6191414809690983 - Train Accuracy:  0.54545456\n",
      "Epoch:  200 - Cost:  0.68900955  - MSE:  1.619141209261729 - Train Accuracy:  0.54545456\n",
      "Epoch:  201 - Cost:  0.6890093  - MSE:  1.6191409810309736 - Train Accuracy:  0.54545456\n",
      "Epoch:  202 - Cost:  0.68900925  - MSE:  1.6191407213095144 - Train Accuracy:  0.54545456\n",
      "Epoch:  203 - Cost:  0.6890091  - MSE:  1.6191405582913287 - Train Accuracy:  0.54545456\n",
      "Epoch:  204 - Cost:  0.6890093  - MSE:  1.6191404170101944 - Train Accuracy:  0.54545456\n",
      "Epoch:  205 - Cost:  0.6890093  - MSE:  1.619140297465557 - Train Accuracy:  0.54545456\n",
      "Epoch:  206 - Cost:  0.68900883  - MSE:  1.6191402637547085 - Train Accuracy:  0.54545456\n",
      "Epoch:  207 - Cost:  0.68900895  - MSE:  1.6191401768142342 - Train Accuracy:  0.54545456\n",
      "Epoch:  208 - Cost:  0.6890093  - MSE:  1.6191401007416906 - Train Accuracy:  0.54545456\n",
      "Epoch:  209 - Cost:  0.6890095  - MSE:  1.6191400355369316 - Train Accuracy:  0.54545456\n",
      "Epoch:  210 - Cost:  0.68900937  - MSE:  1.6191399811998295 - Train Accuracy:  0.54545456\n",
      "Epoch:  211 - Cost:  0.68900937  - MSE:  1.6191399377302744 - Train Accuracy:  0.54545456\n",
      "Epoch:  212 - Cost:  0.689009  - MSE:  1.6191399051281812 - Train Accuracy:  0.54545456\n",
      "Epoch:  213 - Cost:  0.689009  - MSE:  1.619139872526155 - Train Accuracy:  0.54545456\n",
      "Epoch:  214 - Cost:  0.6890091  - MSE:  1.6191398507915054 - Train Accuracy:  0.54545456\n",
      "Epoch:  215 - Cost:  0.6890091  - MSE:  1.6191398290568841 - Train Accuracy:  0.54545456\n",
      "Epoch:  216 - Cost:  0.6890091  - MSE:  1.6191398073222913 - Train Accuracy:  0.54545456\n",
      "Epoch:  217 - Cost:  0.6890091  - MSE:  1.619139785587727 - Train Accuracy:  0.54545456\n",
      "Epoch:  218 - Cost:  0.68900937  - MSE:  1.619139699755267 - Train Accuracy:  0.54545456\n",
      "Epoch:  219 - Cost:  0.6890095  - MSE:  1.619139688888006 - Train Accuracy:  0.54545456\n",
      "Epoch:  220 - Cost:  0.6890095  - MSE:  1.6191396780207523 - Train Accuracy:  0.54545456\n",
      "Epoch:  221 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  222 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  223 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  224 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  225 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  226 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  227 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  228 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  229 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  230 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  231 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  232 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  233 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  234 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  235 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  236 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  237 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  238 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  239 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  240 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  241 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  242 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  243 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  244 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  245 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  246 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  247 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  248 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  249 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  250 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  251 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  252 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  253 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  254 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  255 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  256 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  257 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  258 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  259 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  260 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  261 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  262 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  263 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  264 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  265 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  266 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  267 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  268 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  269 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  270 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  271 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  272 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  273 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  274 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  275 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  276 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  277 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  278 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  279 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  280 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  281 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  282 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  283 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  284 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  285 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  286 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  287 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  288 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  289 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  290 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  291 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  292 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  293 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  294 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  295 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  296 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  297 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  298 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  299 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  300 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  301 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  302 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  303 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  304 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  305 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  306 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  307 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  308 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  309 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  310 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  311 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  312 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  313 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  314 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  315 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  316 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  317 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  318 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  319 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  320 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  321 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  322 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  323 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  324 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  325 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  326 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  327 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  328 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  329 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  330 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  331 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  332 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  333 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  334 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  335 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  336 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  337 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  338 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  339 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  340 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  341 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  342 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  343 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  344 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  345 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  346 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  347 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  348 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  349 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  350 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  351 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  352 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  353 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  354 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  355 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  356 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  357 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  358 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  359 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  360 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  361 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  362 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  363 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  364 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  365 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  366 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  367 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  368 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  369 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  370 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  371 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  372 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  373 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  374 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  375 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  376 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  377 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  378 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  379 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  380 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  381 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  382 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  383 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  384 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  385 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  386 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  387 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  388 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  389 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  390 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  391 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  392 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  393 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  394 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  395 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  396 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  397 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  398 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  399 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  400 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  401 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  402 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  403 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  404 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  405 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  406 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  407 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  408 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  409 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  410 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  411 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  412 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  413 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  414 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  415 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  416 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  417 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  418 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  419 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  420 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  421 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  422 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  423 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  424 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  425 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  426 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  427 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  428 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  429 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  430 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  431 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  432 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  433 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  434 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  435 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  436 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  437 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  438 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  439 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  440 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  441 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  442 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  443 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  444 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  445 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  446 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  447 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  448 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  449 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  450 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  451 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  452 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  453 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  454 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  455 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  456 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  457 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  458 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  459 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  460 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  461 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  462 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  463 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  464 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  465 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  466 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  467 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  468 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  469 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  470 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  471 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  472 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  473 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  474 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  475 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  476 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  477 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  478 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  479 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  480 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  481 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  482 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  483 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  484 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  485 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  486 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  487 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  488 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  489 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  490 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  491 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  492 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  493 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  494 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  495 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  496 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  497 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  498 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  499 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  500 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  501 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  502 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  503 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  504 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  505 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  506 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  507 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  508 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  509 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  510 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  511 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  512 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  513 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  514 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  515 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  516 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  517 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  518 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  519 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  520 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  521 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  522 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  523 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  524 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  525 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  526 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  527 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  528 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  529 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  530 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  531 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  532 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  533 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  534 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  535 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  536 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  537 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  538 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  539 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  540 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  541 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  542 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  543 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  544 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  545 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  546 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  547 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  548 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  549 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  550 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  551 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  552 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  553 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  554 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  555 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  556 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  557 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  558 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  559 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  560 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  561 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  562 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  563 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  564 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  565 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  566 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  567 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  568 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  569 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  570 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  571 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  572 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  573 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  574 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  575 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  576 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  577 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  578 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  579 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  580 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  581 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  582 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  583 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  584 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  585 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  586 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  587 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  588 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  589 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  590 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  591 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  592 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  593 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  594 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  595 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  596 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  597 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  598 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  599 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  600 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  601 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  602 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  603 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  604 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  605 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  606 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  607 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  608 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  609 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  610 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  611 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  612 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  613 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  614 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  615 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  616 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  617 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  618 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  619 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  620 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  621 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  622 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  623 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  624 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  625 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  626 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  627 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  628 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  629 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  630 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  631 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  632 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  633 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  634 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  635 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  636 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  637 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  638 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  639 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  640 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  641 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  642 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  643 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  644 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  645 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  646 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  647 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  648 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  649 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  650 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  651 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  652 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  653 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  654 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  655 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  656 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  657 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  658 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  659 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  660 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  661 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  662 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  663 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  664 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  665 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  666 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  667 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  668 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  669 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  670 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  671 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  672 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  673 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  674 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  675 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  676 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  677 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  678 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  679 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  680 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  681 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  682 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  683 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  684 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  685 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  686 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  687 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  688 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  689 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  690 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  691 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  692 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  693 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  694 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  695 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  696 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  697 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  698 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  699 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  700 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  701 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  702 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  703 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  704 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  705 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  706 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  707 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  708 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  709 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  710 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  711 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  712 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  713 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  714 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  715 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  716 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  717 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  718 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  719 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  720 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  721 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  722 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  723 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  724 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  725 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  726 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  727 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  728 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  729 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  730 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  731 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  732 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  733 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  734 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  735 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  736 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  737 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  738 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  739 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  740 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  741 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  742 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  743 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  744 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  745 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  746 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  747 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  748 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  749 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  750 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  751 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  752 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  753 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  754 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  755 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  756 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  757 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  758 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  759 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  760 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  761 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  762 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  763 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  764 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  765 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  766 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  767 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  768 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  769 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  770 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  771 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  772 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  773 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  774 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  775 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  776 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  777 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  778 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  779 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  780 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  781 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  782 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  783 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  784 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  785 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  786 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  787 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  788 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  789 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  790 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  791 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  792 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  793 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  794 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  795 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  796 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  797 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  798 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  799 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  800 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  801 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  802 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  803 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  804 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  805 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  806 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  807 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  808 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  809 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  810 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  811 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  812 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  813 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  814 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  815 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  816 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  817 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  818 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  819 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  820 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  821 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  822 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  823 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  824 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  825 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  826 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  827 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  828 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  829 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  830 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  831 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  832 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  833 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  834 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  835 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  836 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  837 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  838 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  839 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  840 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  841 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  842 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  843 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  844 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  845 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  846 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  847 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  848 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  849 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  850 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  851 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  852 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  853 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  854 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  855 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  856 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  857 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  858 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  859 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  860 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  861 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  862 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  863 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  864 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  865 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  866 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  867 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  868 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  869 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  870 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  871 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  872 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  873 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  874 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  875 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  876 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  877 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  878 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  879 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  880 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  881 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  882 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  883 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  884 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  885 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  886 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  887 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  888 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  889 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  890 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  891 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  892 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  893 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  894 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  895 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  896 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  897 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  898 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  899 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  900 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  901 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  902 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  903 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  904 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  905 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  906 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  907 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  908 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  909 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  910 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  911 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  912 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  913 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  914 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  915 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  916 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  917 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  918 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  919 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  920 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  921 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  922 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  923 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  924 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  925 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  926 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  927 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  928 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  929 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  930 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  931 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  932 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  933 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  934 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  935 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  936 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  937 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  938 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  939 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  940 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  941 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  942 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  943 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  944 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  945 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  946 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  947 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  948 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  949 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  950 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  951 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  952 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  953 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  954 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  955 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  956 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  957 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  958 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  959 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  960 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  961 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  962 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  963 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  964 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  965 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  966 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  967 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  968 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  969 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  970 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  971 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  972 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  973 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  974 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  975 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  976 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  977 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  978 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  979 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  980 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  981 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  982 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  983 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  984 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  985 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  986 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  987 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  988 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  989 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  990 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  991 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  992 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  993 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  994 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  995 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  996 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  997 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  998 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Epoch:  999 - Cost:  0.6890095  - MSE:  1.6191396671535052 - Train Accuracy:  0.54545456\n",
      "Model saved in file: C:/Users/Heet Gorakhitya/Desktop\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sess.run(training_step, feed_dict={x: train_x, y_: train_y})\n",
    "    cost = sess.run(cost_function, feed_dict={x: train_x, y_: train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = sess.run(accuracy, feed_dict={x: train_x, y_: train_y})\n",
    "    accuracy_history.append(accuracy)\n",
    "    print(\"Epoch: \", epoch, \"-\", \"Cost: \", cost, \" - MSE: \", mse_, \"- Train Accuracy: \", accuracy)\n",
    "\n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x280b31cd390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCn4RkYxR8IuIZMz/B5eZGnoE5fTIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x280cd51fd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_history, \"r\")\n",
    "plt.show()\n",
    "plt.plot(accuracy_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.5\n",
      "MSE: 2.1640\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Test Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    "\n",
    "pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "print(\"MSE: %.4f\" % sess.run(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
